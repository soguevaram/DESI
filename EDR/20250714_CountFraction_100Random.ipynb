{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94d1394a-26dc-42ec-a1df-890d2d077e67",
   "metadata": {},
   "source": [
    "<style>\n",
    "body {\n",
    "    font-size: 20pt !important;\n",
    "}\n",
    "\n",
    ".rendered_html {\n",
    "    font-size: 20pt !important;\n",
    "}\n",
    "\n",
    ".CodeMirror pre {\n",
    "    font-size: 20pt !important;\n",
    "}\n",
    "\n",
    ".output pre {\n",
    "    font-size: 20pt !important;\n",
    "}\n",
    "</style>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61037cf-6d2b-408d-840e-d6427fc49e80",
   "metadata": {},
   "source": [
    "<h2 style=\"font-size:24pt\"> Proyecto DESI</h2>\n",
    "\n",
    "<h2 style=\"font-size:24pt\"> Julio 14, 2025</h2>\n",
    "\n",
    "<p style=\"font-size:16pt\">\n",
    "Calculation of the count fraction for 100 random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3efb79ce-611d-4070-a96d-15e81378315e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.tri as mtri\n",
    "from scipy.spatial import Delaunay\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.table import Table\n",
    "from astropy.io import ascii\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61193c0-f5f3-442b-856e-6b36b2bed956",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "670abbe5-eaaf-46ac-a358-4ab771cfa942",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "for i in range(20):\n",
    "    file = f\"data_rosette/LRG_{i}_clustering_data.ecsv\"\n",
    "    table = Table.read(file, format=\"ascii.ecsv\")\n",
    "    data[f'data_{i}'] = table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e8ac4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_r(data_all):\n",
    "    df_tri = data_all[['x', 'y', 'z']].values\n",
    "    tri = Delaunay(df_tri)\n",
    "\n",
    "    G = nx.Graph()\n",
    "    ids = data_all['TARGETID'].values\n",
    "    types = data_all['type'].values\n",
    "\n",
    "    G.add_nodes_from(\n",
    "        (id_, {\"pos\": tuple(coord), \"type\": tipo})\n",
    "        for id_, coord, tipo in zip(ids, df_tri, types)\n",
    "    )\n",
    "\n",
    "    G.add_edges_from(\n",
    "        (ids[simplex[i]], ids[simplex[j]])\n",
    "        for simplex in tri.simplices\n",
    "        for i in range(3)\n",
    "        for j in range(i + 1, 4)\n",
    "    )\n",
    "\n",
    "    degree_dict = dict(G.degree())\n",
    "    data_all['degree'] = data_all['TARGETID'].map(degree_dict)\n",
    "\n",
    "    node_types = nx.get_node_attributes(G, 'type')\n",
    "\n",
    "    n_data_dict = {}\n",
    "    n_random_dict = {}\n",
    "    data_neighbors_dict = {}\n",
    "    rand_neighbors_dict = {}\n",
    "\n",
    "    for node in G.nodes:\n",
    "        neighbors = list(G.neighbors(node))\n",
    "\n",
    "        data_ids = [n for n in neighbors if node_types[n] == 'data']\n",
    "        rand_ids = [n for n in neighbors if node_types[n] == 'rand']\n",
    "\n",
    "        n_data_dict[node] = len(data_ids)\n",
    "        n_random_dict[node] = len(rand_ids)\n",
    "        data_neighbors_dict[node] = \",\".join(map(str, data_ids))\n",
    "        rand_neighbors_dict[node] = \",\".join(map(str, rand_ids))\n",
    "\n",
    "    data_all['N_data'] = data_all['TARGETID'].map(n_data_dict)\n",
    "    data_all['N_random'] = data_all['TARGETID'].map(n_random_dict)\n",
    "    data_all['neighbor_ids_data'] = data_all['TARGETID'].map(data_neighbors_dict)\n",
    "    data_all['neighbor_ids_rand'] = data_all['TARGETID'].map(rand_neighbors_dict)\n",
    "\n",
    "    total = data_all['N_data'] + data_all['N_random']\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        r = np.where(total > 0, (data_all['N_data'] - data_all['N_random']) / total, 0)\n",
    "\n",
    "    data_all['r'] = r\n",
    "\n",
    "    return data_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8de7a1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification(data):\n",
    "    data['classification'] = 'unclassified'\n",
    "\n",
    "    data.loc[(data['r'] >= -1.0) & (data['r'] <= -0.9), 'classification'] = 'void'\n",
    "    data.loc[(data['r'] >  -0.9) & (data['r'] <=  0.0), 'classification'] = 'sheet'\n",
    "    data.loc[(data['r'] >   0.0) & (data['r'] <=  0.9), 'classification'] = 'filament'\n",
    "    data.loc[(data['r'] >   0.9) & (data['r'] <=  1.0), 'classification'] = 'knot'\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2d24746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_classification(data):\n",
    "    void     = data[data['classification'] == 'void']\n",
    "    sheet    = data[data['classification'] == 'sheet']\n",
    "    filament = data[data['classification'] == 'filament']\n",
    "    knot     = data[data['classification'] == 'knot']\n",
    "\n",
    "    return (void,sheet,filament,knot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f886c5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_fraction(data,type_data):\n",
    "    \n",
    "    data_filtered = data[data['type'] == type_data]\n",
    "    parts = mask_classification(data_filtered)\n",
    "    void, sheet, filament, knot = parts\n",
    "            \n",
    "    void_perc = len(void) / len (data_filtered) * 100    \n",
    "    sheet_perc = len(sheet) / len (data_filtered) * 100 \n",
    "    filament_perc = len(filament) / len (data_filtered) * 100 \n",
    "    knot_perc = len(knot) / len (data_filtered) * 100 \n",
    "\n",
    "    return void_perc,sheet_perc,filament_perc,knot_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fceefca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rosette 0\n",
      "Rosette 1\n",
      "Rosette 2\n",
      "Rosette 3\n",
      "Rosette 4\n",
      "Rosette 5\n",
      "Rosette 6\n",
      "Rosette 7\n",
      "Rosette 8\n",
      "Rosette 9\n",
      "Rosette 10\n",
      "Rosette 11\n",
      "Rosette 12\n",
      "Rosette 13\n",
      "Rosette 14\n",
      "Rosette 15\n",
      "Rosette 16\n",
      "Rosette 17\n",
      "Rosette 18\n",
      "Rosette 19\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "number_random = 100\n",
    "num_rosettes = 20\n",
    "base_path = Path(\"rand_rosette\")\n",
    "\n",
    "mean_values_data = {}\n",
    "std_values_data = {}\n",
    "mean_values_rand = {}\n",
    "std_values_rand = {}\n",
    "\n",
    "for i in range(num_rosettes):\n",
    "    print(f'Rosette {i}')\n",
    "    \n",
    "    perc_data_list = []\n",
    "    perc_rand_list = []\n",
    "\n",
    "    df_data = data[f'data_{i}'][['TARGETID', 'RA', 'DEC', 'Z', 'x', 'y', 'z']].to_pandas().copy()\n",
    "    df_data['type'] = 'data'\n",
    "\n",
    "    for j in range(number_random):\n",
    "\n",
    "        file = base_path / f\"LRG_rosette_{i}_random_{j}.ecsv\"\n",
    "        subset = Table.read(file, format=\"ascii.ecsv\")[['TARGETID', 'RA', 'DEC', 'Z', 'x', 'y', 'z']].to_pandas()\n",
    "        subset['type'] = 'rand'\n",
    "\n",
    "        df_concat = pd.concat([subset, df_data], ignore_index=True)\n",
    "\n",
    "        data_with_class = classification(parameter_r(df_concat))\n",
    "\n",
    "        void_d, sheet_d, fil_d, knot_d = count_fraction(data_with_class, 'data')\n",
    "        void_r, sheet_r, fil_r, knot_r = count_fraction(data_with_class, 'rand')\n",
    "\n",
    "        perc_data_list.append([void_d, sheet_d, fil_d, knot_d])\n",
    "        perc_rand_list.append([void_r, sheet_r, fil_r, knot_r])\n",
    "\n",
    "    perc_data_arr = np.array(perc_data_list)\n",
    "    perc_rand_arr = np.array(perc_rand_list)\n",
    "\n",
    "    mean_values_data[i] = perc_data_arr.mean(axis=0)\n",
    "    std_values_data[i]  = perc_data_arr.std(axis=0)\n",
    "\n",
    "    mean_values_rand[i] = perc_rand_arr.mean(axis=0)\n",
    "    std_values_rand[i]  = perc_rand_arr.std(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b43419a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== DATOS REALES =====\n",
      "               Void (%)     Sheet (%)  Filament (%)     Knot (%)\n",
      "Rosette 0   0.18 ± 0.06  41.54 ± 0.56  56.03 ± 0.59  2.24 ± 0.26\n",
      "Rosette 1   0.16 ± 0.04  44.21 ± 0.60  53.96 ± 0.62  1.68 ± 0.18\n",
      "Rosette 2   0.26 ± 0.06  41.40 ± 0.60  56.67 ± 0.62  1.66 ± 0.18\n",
      "Rosette 3   0.17 ± 0.05  41.99 ± 0.62  56.49 ± 0.63  1.35 ± 0.15\n",
      "Rosette 4   0.18 ± 0.05  42.44 ± 0.64  55.70 ± 0.64  1.69 ± 0.17\n",
      "Rosette 5   0.20 ± 0.05  43.06 ± 0.60  55.28 ± 0.61  1.46 ± 0.18\n",
      "Rosette 6   0.18 ± 0.05  43.49 ± 0.55  55.13 ± 0.56  1.20 ± 0.15\n",
      "Rosette 7   0.19 ± 0.05  43.45 ± 0.60  54.65 ± 0.60  1.70 ± 0.18\n",
      "Rosette 8   0.17 ± 0.05  43.18 ± 0.62  54.90 ± 0.63  1.76 ± 0.17\n",
      "Rosette 9   0.21 ± 0.05  42.20 ± 0.54  55.84 ± 0.57  1.75 ± 0.18\n",
      "Rosette 10  0.20 ± 0.05  42.36 ± 0.59  55.58 ± 0.61  1.87 ± 0.22\n",
      "Rosette 11  0.16 ± 0.05  43.22 ± 0.55  54.94 ± 0.58  1.68 ± 0.21\n",
      "Rosette 12  0.18 ± 0.04  42.30 ± 0.52  55.93 ± 0.55  1.59 ± 0.22\n",
      "Rosette 13  0.17 ± 0.06  44.60 ± 0.62  53.85 ± 0.61  1.39 ± 0.20\n",
      "Rosette 14  0.21 ± 0.06  43.43 ± 0.58  54.63 ± 0.61  1.72 ± 0.23\n",
      "Rosette 15  0.11 ± 0.04  44.10 ± 0.58  54.33 ± 0.58  1.47 ± 0.17\n",
      "Rosette 16  0.17 ± 0.05  44.52 ± 0.57  54.12 ± 0.55  1.19 ± 0.15\n",
      "Rosette 17  0.21 ± 0.05  42.13 ± 0.60  56.47 ± 0.59  1.19 ± 0.12\n",
      "Rosette 18  0.17 ± 0.06  43.46 ± 0.65  54.56 ± 0.68  1.81 ± 0.21\n",
      "Rosette 19  0.23 ± 0.05  42.70 ± 0.52  55.79 ± 0.56  1.28 ± 0.14\n"
     ]
    }
   ],
   "source": [
    "columnas = [\"Void (%)\", \"Sheet (%)\", \"Filament (%)\", \"Knot (%)\"]\n",
    "\n",
    "filas = []\n",
    "indices = []\n",
    "\n",
    "for i in mean_values_data.keys():\n",
    "    mean = mean_values_data[i]\n",
    "    std  = std_values_data[i]\n",
    "    fila = [f\"{m:.2f} ± {s:.2f}\" for m, s in zip(mean, std)]\n",
    "    filas.append(fila)\n",
    "    indices.append(f\"Rosette {i}\")\n",
    "\n",
    "tabla_final = pd.DataFrame(filas, columns=columnas, index=indices)\n",
    "\n",
    "print(\"===== DATOS REALES =====\")\n",
    "print(tabla_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9346c788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== DATOS RANDOM =====\n",
      "               Void (%)     Sheet (%)  Filament (%)     Knot (%)\n",
      "Rosette 0   1.66 ± 0.18  73.41 ± 0.48  24.81 ± 0.48  0.11 ± 0.04\n",
      "Rosette 1   1.21 ± 0.14  72.68 ± 0.46  26.03 ± 0.45  0.09 ± 0.04\n",
      "Rosette 2   1.72 ± 0.17  72.29 ± 0.54  25.89 ± 0.51  0.10 ± 0.04\n",
      "Rosette 3   1.99 ± 0.22  71.09 ± 0.63  26.83 ± 0.55  0.09 ± 0.04\n",
      "Rosette 4   1.78 ± 0.20  72.50 ± 0.57  25.63 ± 0.49  0.10 ± 0.05\n",
      "Rosette 5   2.10 ± 0.19  71.40 ± 0.51  26.42 ± 0.51  0.08 ± 0.04\n",
      "Rosette 6   1.22 ± 0.16  72.57 ± 0.47  26.13 ± 0.44  0.09 ± 0.04\n",
      "Rosette 7   1.16 ± 0.16  72.96 ± 0.48  25.79 ± 0.47  0.10 ± 0.04\n",
      "Rosette 8   1.54 ± 0.18  73.49 ± 0.50  24.88 ± 0.44  0.10 ± 0.04\n",
      "Rosette 9   1.74 ± 0.18  72.74 ± 0.45  25.43 ± 0.41  0.10 ± 0.03\n",
      "Rosette 10  1.56 ± 0.19  73.40 ± 0.50  24.93 ± 0.46  0.11 ± 0.04\n",
      "Rosette 11  1.41 ± 0.17  72.89 ± 0.56  25.59 ± 0.50  0.10 ± 0.04\n",
      "Rosette 12  1.74 ± 0.18  72.58 ± 0.55  25.57 ± 0.50  0.10 ± 0.04\n",
      "Rosette 13  1.28 ± 0.17  72.70 ± 0.48  25.94 ± 0.46  0.08 ± 0.03\n",
      "Rosette 14  1.26 ± 0.17  73.36 ± 0.50  25.29 ± 0.48  0.09 ± 0.04\n",
      "Rosette 15  1.40 ± 0.17  72.66 ± 0.46  25.85 ± 0.45  0.08 ± 0.04\n",
      "Rosette 16  1.58 ± 0.16  71.24 ± 0.49  27.11 ± 0.46  0.07 ± 0.03\n",
      "Rosette 17  1.33 ± 0.18  72.90 ± 0.51  25.70 ± 0.47  0.06 ± 0.03\n",
      "Rosette 18  1.22 ± 0.20  73.38 ± 0.55  25.31 ± 0.49  0.09 ± 0.04\n",
      "Rosette 19  1.47 ± 0.17  72.24 ± 0.56  26.21 ± 0.49  0.07 ± 0.03\n"
     ]
    }
   ],
   "source": [
    "columnas = [\"Void (%)\", \"Sheet (%)\", \"Filament (%)\", \"Knot (%)\"]\n",
    "\n",
    "filas = []\n",
    "indices = []\n",
    "\n",
    "for i in mean_values_rand.keys():\n",
    "    mean = mean_values_rand[i]\n",
    "    std  = std_values_rand[i]\n",
    "    fila = [f\"{m:.2f} ± {s:.2f}\" for m, s in zip(mean, std)]\n",
    "    filas.append(fila)\n",
    "    indices.append(f\"Rosette {i}\")\n",
    "\n",
    "tabla_final = pd.DataFrame(filas, columns=columnas, index=indices)\n",
    "\n",
    "print(\"===== DATOS RANDOM =====\")\n",
    "print(tabla_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24b2daf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio Datos reales\n",
      "Void (%): 0.19 ± 0.03\n",
      "Sheet (%): 42.99 ± 0.92\n",
      "Filament (%): 55.24 ± 0.85\n",
      "Knot (%): 1.58 ± 0.26\n"
     ]
    }
   ],
   "source": [
    "all_means = np.vstack(list(mean_values_data.values()))  # stack de todos los arrays\n",
    "\n",
    "global_mean = all_means.mean(axis=0)\n",
    "global_std = all_means.std(axis=0)\n",
    "\n",
    "columnas = [\"Void (%)\", \"Sheet (%)\", \"Filament (%)\", \"Knot (%)\"]\n",
    "print('Promedio Datos reales')\n",
    "for col, m, s in zip(columnas, global_mean, global_std):\n",
    "    print(f\"{col}: {m:.2f} ± {s:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c30612d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio Datos random\n",
      "Void (%): 1.52 ± 0.26\n",
      "Sheet (%): 72.62 ± 0.69\n",
      "Filament (%): 25.77 ± 0.59\n",
      "Knot (%): 0.09 ± 0.01\n"
     ]
    }
   ],
   "source": [
    "all_means = np.vstack(list(mean_values_rand.values()))  # stack de todos los arrays\n",
    "\n",
    "global_mean = all_means.mean(axis=0)\n",
    "global_std = all_means.std(axis=0)\n",
    "\n",
    "columnas = [\"Void (%)\", \"Sheet (%)\", \"Filament (%)\", \"Knot (%)\"]\n",
    "print('Promedio Datos random')\n",
    "for col, m, s in zip(columnas, global_mean, global_std):\n",
    "    print(f\"{col}: {m:.2f} ± {s:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
